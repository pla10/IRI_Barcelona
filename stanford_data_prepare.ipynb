{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "\n",
    "# Configuration parameters\n",
    "MAP_DIR = 'maps/13semantics/'  # Output directory\n",
    "DT = 0.5  # Simulated time step \n",
    "ALPHA = 0.2  # Velocity smoothing factor\n",
    "\n",
    "# Semantic classes\n",
    "SEM_DICT = [\n",
    "    'bicycle_road', \n",
    "    'building', \n",
    "    'entrance', \n",
    "    'grass', \n",
    "    'obstacle', \n",
    "    'parking', \n",
    "    'pedestrian_road', \n",
    "    'tree', \n",
    "    'vehicle_road',\n",
    "    'sitting_area',\n",
    "    'stairs',\n",
    "    'intersection_zone',\n",
    "]\n",
    "\n",
    "# Function to process a single map\n",
    "def process_map(map_name, red, directory_dataset):\n",
    "    \"\"\"\n",
    "    Generates human density, velocity, and stop maps for a given map.\n",
    "\n",
    "    Args:\n",
    "        map_name (str): Name of the map (e.g., 'stanford_bookstore0')\n",
    "        red (int): Image reduction factor, should be consistent with map scale\n",
    "        directory_dataset (str): Path to the video and annotation data\n",
    "    \"\"\"\n",
    "\n",
    "    # Load video and annotations\n",
    "    video_path = '/data/placido/Stanford_Drone_Dataset/video' + directory_dataset + 'video.mp4'\n",
    "    anno_path = '/data/placido/Stanford_Drone_Dataset/annotations' + directory_dataset + 'annotations.txt'\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video stream or file\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_csv(anno_path, delimiter=' ', header=None)\n",
    "\n",
    "    # Extract reference frame\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 1000)  # Adjust frame position if needed\n",
    "    ret, ref_frame = cap.read()\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs('maps/13semantics/'+map_name, exist_ok=True)\n",
    "    cv2.imwrite(os.path.join(MAP_DIR, map_name, 'reference.png'), ref_frame)\n",
    "\n",
    "    # Initialize data maps\n",
    "    h, w = ref_frame.shape[:2]\n",
    "    data = np.zeros((h // red, w // red))\n",
    "    data_vel = np.zeros((h // red, w // red))\n",
    "    data_stops = np.zeros((h // red, w // red))\n",
    "\n",
    "    # Scale ratios for annotations\n",
    "    ratioy = df[4].max() / h\n",
    "    ratiox = df[3].max() / w\n",
    "\n",
    "    # Filter for pedestrians only\n",
    "    ped_df = df[df[9] == 'Pedestrian'].reset_index()\n",
    "\n",
    "    # Process pedestrian tracks\n",
    "    for trackid in ped_df[0].unique():\n",
    "        data_temp = np.zeros((h // red, w // red))\n",
    "        vel_temp = np.zeros((h // red, w // red))\n",
    "        stop_temp = np.zeros((h // red, w // red))\n",
    "        vtemp = 0\n",
    "\n",
    "        track_df = ped_df[ped_df[0] == trackid].reset_index()\n",
    "        pos = {'x': 0, 'y': 0}  # Initialize position\n",
    "        vel = {'x': 0, 'y': 0}  # Initialize velocity\n",
    "\n",
    "        for _, row in track_df.iterrows():\n",
    "            center = (int((row[2] + row[4]) / 2 / ratioy / red), int((row[1] + row[3]) / 2 / ratiox / red)) \n",
    "\n",
    "            if center[0] < data.shape[0] and center[1] < data.shape[1] and (row[6] == 0 or row[7] == 1):\n",
    "                # Update position and velocity\n",
    "                prev_pos = pos.copy()  # Keep a copy of the previous position\n",
    "                pos = {'x': center[0], 'y': center[1]}  # Create a new position dictionary\n",
    "                vel = {\n",
    "                    'x': ALPHA * (pos['x'] - prev_pos['x']) / DT + (1 - ALPHA) * vel['x'],\n",
    "                    'y': ALPHA * (pos['y'] - prev_pos['y']) / DT + (1 - ALPHA) * vel['y']\n",
    "                }\n",
    "\n",
    "                # Update maps\n",
    "                data_temp[center] = 1\n",
    "                old_vtemp = vtemp if vtemp < 1 else old_vtemp\n",
    "                vtemp = math.sqrt(vel['x']**2 + vel['y']**2)\n",
    "                vtemp = vtemp if vtemp < 1 else old_vtemp # Filter out high-speed outliers\n",
    "                vel_temp[center] = np.max([vel_temp[center],vtemp])\n",
    "                stop_temp[center] = 1 if vtemp < 1e-20 and vtemp > 1e-100 else 0\n",
    "\n",
    "        data = data + data_temp\n",
    "        data_vel = data_vel * (vel_temp == 0) + data_vel * (vel_temp > 0)*0.5 + vel_temp * (data_vel > 0)*0.5 + vel_temp * (data_vel == 0)\n",
    "        data_stops = data_stops + stop_temp        \n",
    "\n",
    "    # Normalize and visualize density map\n",
    "    data /= np.max(data)\n",
    "    ref_frame_red = cv2.resize(ref_frame, (w // red, h // red), interpolation=cv2.INTER_AREA) / 510 + 0.5\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.imshow(np.multiply(ref_frame_red, np.stack((np.full(data.shape, 1), 1 - data, 1 - data), axis=2)))\n",
    "    # plt.imshow(data)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Save density map\n",
    "    np.savetxt(os.path.join(MAP_DIR, map_name, 'humandensity-' + map_name + '-new.csv'), data * 255, delimiter=',', fmt='%3d')\n",
    "    cv2.imwrite(os.path.join(MAP_DIR, map_name, 'humandensity-' + map_name + '-new.png'), data * 255)\n",
    "\n",
    "    # Normalize and visualize velocity map\n",
    "    data_vel /= np.max(data_vel)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.imshow(np.multiply(ref_frame_red, np.stack((np.full(data_vel.shape, 1), 1 - data_vel, 1 - data_vel), axis=2)))\n",
    "    # plt.imshow(data_vel)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Save velocity map\n",
    "    np.savetxt(os.path.join(MAP_DIR, map_name,  'humandensity-' + map_name + '-vel.csv'), data_vel, delimiter=',', fmt='%f')\n",
    "\n",
    "    # Normalize and visualize stop map\n",
    "    data_stops /= np.max(data_stops)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.imshow(np.multiply(ref_frame_red, np.stack((np.full(data_stops.shape, 1), 1 - data_stops, 1 - data_stops), axis=2)))\n",
    "    # plt.imshow(data_stops)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Save stop map\n",
    "    np.savetxt(os.path.join(MAP_DIR, map_name, 'humandensity-' + map_name + '-stop.csv'), data_stops, delimiter=',', fmt='%f')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage (assuming data structure from your original code)\n",
    "    locations = ['bookstore', 'bookstore', 'coupa', 'coupa', 'coupa', 'coupa', 'gates', 'gates', 'gates', 'gates', 'hyang', 'hyang', 'hyang', 'hyang', 'little', 'nexus', 'nexus', 'deathCircle']\n",
    "    numbers =   [        '0',         '4',     '0',     '1',     '2',     '3',     '0',     '1',     '2',     '3',     '2',     '3',     '4',    '10',      '3',     '0',     '1',           '0']\n",
    "    reds =      [        11 ,         12 ,     14 ,     14 ,     14 ,     16 ,      5 ,      6 ,      6 ,      7 ,      7 ,      7 ,      7 ,      7 ,       7 ,      5 ,      5 ,            6 ]\n",
    "\n",
    "    for location, number, red in zip(locations, numbers, reds):\n",
    "        map_name = 'stanford_' + location + number\n",
    "        directory_dataset = '/' + location + '/video' + number + '/'\n",
    "        process_map(map_name, red, directory_dataset)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
