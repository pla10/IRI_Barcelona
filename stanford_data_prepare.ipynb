{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# import tensorflow as tf\n",
    "\n",
    "# from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import skimage.measure\n",
    "\n",
    "import random\n",
    "import copy\n",
    "import math\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# %%\n",
    "idx = 7\n",
    "if True:\n",
    "# for idx in range(13):\n",
    "  \n",
    "  div = 32\n",
    "  step = int(32/4)\n",
    "  #      0    1   2   3   4  5   6  7  8  9 10 11 12 13 14 15\n",
    "  red = [11, 12, 14, 14, 14, 16, 6, 7, 7, 7, 7, 7, 7, 5, 5, 6] # Check the estimated_scales.yaml -> the resolution has to be 0.4 meters/pixel\n",
    "  red = red[idx]\n",
    "  #                   0           1             2         3        4        5        6       7         8        9        10        11       12       13        14       15\n",
    "  location_list = ['bookstore', 'bookstore', 'coupa', 'coupa', 'coupa', 'coupa', 'gates', 'gates', 'hyang', 'hyang', 'hyang', 'hyang', 'little', 'nexus', 'nexus', 'deathCircle']\n",
    "  number_list =   ['0',               '4',      '0',      '1',      '2',     '3',    '2',    '6',     '2',     '3',     '4',     '10',    '3',     '0',     '1',        '0']\n",
    "\n",
    "  # semantic class cash is used also for bike parking spots\n",
    "  # sem_dict = ['cash', 'entrance', 'light', 'sit', 'stairs', 'trash', 'tree','restricted','grass','intersection','shadow']\n",
    "  sem_dict = ['bicycle_road', 'building', 'entrance', 'grass', 'obstacle', 'parking', 'pedestrian_road', 'tree', 'vehicle_road']\n",
    "  \n",
    "  chans = len(sem_dict)\n",
    "\n",
    "  lut_in = [0, 20, 50, 100, 150, 255]\n",
    "  lut_out = [0, 100, 180, 220, 240, 255]\n",
    "  lut_8u = np.interp(np.arange(0, 256), lut_in, lut_out).astype(np.uint8)\n",
    "\n",
    "  location = location_list[idx]\n",
    "  number = number_list[idx]\n",
    "  map_name = 'stanford_'+location+number\n",
    "  directory_dataset = '/'+location+'/video'+number+'/'\n",
    "  print(map_name)\n",
    "\n",
    "  # %%\n",
    "  # Code to check if the red variable is correct to scale to the correct homography. Check on google maps and note that each pixel should be 0.4 meters (32 pixels = 12.8m)\n",
    "\n",
    "  cap = cv2.VideoCapture('/data/placido/Stanford_Drone_Dataset/video'+directory_dataset+'video.mp4')\n",
    "  df = pd.read_csv('/data/placido/Stanford_Drone_Dataset/annotations'+directory_dataset+'annotations.txt', delimiter=' ', header=None)\n",
    "  \n",
    "  # Check if camera opened successfully\n",
    "  if (cap.isOpened()== False): \n",
    "    print(\"Error opening video stream or file\")\n",
    "  cap.set(cv2.CAP_PROP_POS_FRAMES, 1000)\n",
    "  ret, frame = cap.read()\n",
    "  # Create the output directory if it doesn't exist\n",
    "  os.makedirs('maps/semantics/'+map_name, exist_ok=True)\n",
    "  cv2.imwrite('maps/semantics/'+map_name+'/reference.png', frame)\n",
    "  ref_frame = frame\n",
    "  cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "  print(frame.shape)\n",
    "  h = frame.shape[0]\n",
    "  w = frame.shape[1]\n",
    "\n",
    "  frame = skimage.measure.block_reduce(frame, (red,red,1), np.max)\n",
    "\n",
    "  print(frame.shape)\n",
    "\n",
    "  plt.figure()\n",
    "  plt.imshow(frame)\n",
    "  plt.show()\n",
    "\n",
    "  dt = 1/cap.get(cv2.CAP_PROP_FPS)\n",
    "  dt = 0.5\n",
    "  # When everything done, release the video capture object\n",
    "  cap.release()\n",
    "\n",
    "  data = np.zeros((h,w))\n",
    "  data_vel = np.zeros((h,w))\n",
    "  data_stops = np.zeros((h,w))\n",
    "  pos = {'x': 0.0, 'y': 0.0}\n",
    "  vel = {'x': 0.0, 'y': 0.0}\n",
    "\n",
    "  ratioy = (df[4].max())/h\n",
    "  ratiox = (df[3].max())/w\n",
    "\n",
    "  ped = df[df[9]=='Pedestrian']# filter only people\n",
    "  ped = ped.reset_index()\n",
    "\n",
    "  alpha = 0.2\n",
    "  for trackid in ped[0].unique():\n",
    "    ce = ped[ped[0]==trackid]\n",
    "    ce = ce.reset_index()\n",
    "\n",
    "    data_temp = np.zeros((h,w))\n",
    "    vel_temp = np.zeros((h,w))\n",
    "    stop_temp = np.zeros((h,w))\n",
    "    for index, el in ce.iterrows():\n",
    "      centerOfCircle = (int((el[2]+el[4])/2/ratioy),int((el[1]+el[3])/2/ratiox))\n",
    "      if index==0:\n",
    "        pos = {'x': centerOfCircle[0],'y': centerOfCircle[1]}\n",
    "      vel = {'x': alpha*(centerOfCircle[0]-pos['x'])/dt/red + (1-alpha)*vel['x'],'y': alpha*(centerOfCircle[1]-pos['y'])/dt/red + (1-alpha)*vel['y']}\n",
    "      pos = {'x': centerOfCircle[0],'y': centerOfCircle[1]}\n",
    "\n",
    "      if centerOfCircle[0] < h and centerOfCircle[1] < w and (el[6] == 0 or el[7] == 1):\n",
    "        data_temp[centerOfCircle] = 1\n",
    "        if index > 0:\n",
    "          vel_temp[centerOfCircle] = math.sqrt(vel['x']**2+vel['y']**2)\n",
    "          if(vel_temp[centerOfCircle] < 1e-30):\n",
    "            stop_temp[centerOfCircle] = 1\n",
    "\n",
    "    if np.max(vel_temp) < 1.5:\n",
    "      data_vel = data_vel * (vel_temp == 0) + data_vel * (vel_temp > 0)*0.5 + vel_temp * (data_vel > 0)*0.5 + vel_temp * (data_vel == 0)\n",
    "      data = data + data_temp\n",
    "      data_stops = data_stops + stop_temp\n",
    "    # else:\n",
    "    #   print('VEL EXEEDS 2')\n",
    "\n",
    "  # data = np.clip(data,0,np.max(data)*0.2)/(np.max(data)*0.2)\n",
    "  # data = cv2.LUT((data/np.max(data)*255).astype(np.uint8), lut_8u).astype(float)/255\n",
    "  ref_frame_red = skimage.measure.block_reduce(ref_frame, (red,red,1), np.max)/510+0.5\n",
    "  plt.figure(figsize=(6,5))\n",
    "  data_show = data/np.max(data)\n",
    "  plt.imshow(np.multiply(ref_frame/510+0.5, np.stack((np.full(data_show.shape,1),1-data_show,1-data_show),axis=2)), vmin=0, vmax=255)\n",
    "  plt.show()\n",
    "  data = skimage.measure.block_reduce(data, (red,red), np.max)\n",
    "  print(f'data max: {np.max(data)}')\n",
    "  print(f'data min: {np.min(data)}')\n",
    "  data_show = data/np.max(data)\n",
    "\n",
    "  # data = np.subtract(data, np.full((data.shape[0], data.shape[1]), np.min(data)))/(np.max(data)-np.min(data))\n",
    "\n",
    "  plt.figure(figsize=(6,5))\n",
    "  # plt.imshow(np.multiply(np.stack((map_var[:,:,0],map_var[:,:,0],map_var[:,:,0]),axis=2), np.stack((np.full(data.shape,1),1-data,1-data),axis=2)))\n",
    "  plt.imshow(np.multiply(ref_frame_red, np.stack((np.full(data_show.shape,1),1-data_show,1-data_show),axis=2)))\n",
    "  plt.show()\n",
    "\n",
    "  np.savetxt('maps/semantics/'+map_name+'/humandensity-'+map_name+'-new.csv', data*255, delimiter=',', fmt='%3d')\n",
    "\n",
    "  # -----------------------------------------------------------------------------------\n",
    "\n",
    "  data_vel = skimage.measure.block_reduce(data_vel, (red,red), np.max)\n",
    "  print(f'data_vel max: {np.max(data_vel)}')\n",
    "  print(f'data_vel min: {np.min(data_vel)}')\n",
    "  data_vel_show = data_vel/np.max(data_vel)\n",
    "  # data_vel = np.subtract(data_vel, np.full((data.shape[0], data.shape[1]), np.min(data_vel)))/(np.max(data_vel)-np.min(data_vel))\n",
    "\n",
    "  plt.figure(figsize=(6,5))\n",
    "  # plt.imshow(np.multiply(np.stack((map_var[:,:,0],map_var[:,:,0],map_var[:,:,0]),axis=2), np.stack((np.full(data_vel.shape,1),1-data_vel,1-data_vel),axis=2)))\n",
    "  plt.imshow(np.multiply(ref_frame_red, np.stack((np.full(data_vel_show.shape,1),1-data_vel_show,1-data_vel_show),axis=2)))\n",
    "  plt.show()\n",
    "\n",
    "  np.savetxt('maps/semantics/'+map_name+'/humandensity-'+map_name+'-vel.csv', data_vel*255, delimiter=',', fmt='%3d')\n",
    "\n",
    "  # -----------------------------------------------------------------------------------\n",
    "\n",
    "  data_stops = skimage.measure.block_reduce(data_stops, (red,red), np.max)\n",
    "  print(f'data_stops max: {np.max(data_stops)}')\n",
    "  print(f'data_stops min: {np.min(data_stops)}')\n",
    "  data_stops_show = data_stops/np.max(data_stops)\n",
    "  # data_stops = np.subtract(data_stops, np.full((data.shape[0], data.shape[1]), np.min(data_stops)))/(np.max(data_stops)-np.min(data_stops))\n",
    "\n",
    "  plt.figure(figsize=(6,5))\n",
    "  # plt.imshow(np.multiply(np.stack((map_var[:,:,0],map_var[:,:,0],map_var[:,:,0]),axis=2), np.stack((np.full(data_stops.shape,1),1-data_stops,1-data_stops),axis=2)))\n",
    "  plt.imshow(np.multiply(ref_frame_red, np.stack((np.full(data_stops_show.shape,1),1-data_stops_show,1-data_stops_show),axis=2)))\n",
    "  plt.show()\n",
    "\n",
    "  np.savetxt('maps/semantics/'+map_name+'/humandensity-'+map_name+'-stop.csv', data_stops*255, delimiter=',', fmt='%3d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
