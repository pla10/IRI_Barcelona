{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for the training of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 11:46:52.361481: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-22 11:46:52.391795: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-22 11:46:52.391821: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-22 11:46:52.392656: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-22 11:46:52.398118: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-22 11:46:53.013969: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import skimage.measure\n",
    "from datetime import datetime\n",
    "\n",
    "import random\n",
    "import copy\n",
    "import math\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22feb\n"
     ]
    }
   ],
   "source": [
    "div = 64\n",
    "step = int(32/4)\n",
    "\n",
    "map_list = ['stanford_bookstore0', 'stanford_bookstore4', 'stanford_coupa0', 'stanford_coupa1', \n",
    "            'stanford_coupa2', 'stanford_coupa3', 'stanford_gates2', 'stanford_gates6', \n",
    "            'stanford_hyang2', 'stanford_hyang3', 'stanford_hyang4', 'stanford_hyang10', \n",
    "            'stanford_little3',  'stanford_nexus0',  'stanford_nexus1', 'stanford_deathCircle0']\n",
    "\n",
    "# sem_dict = ['cash', 'entrance', 'light', 'sit', 'stairs', 'trash', 'tree','restricted','grass','intersection','shadow']\n",
    "sem_dict = ['bicycle_road', 'building', 'entrance', 'grass', 'obstacle', 'parking', 'pedestrian_road', 'tree', 'vehicle_road']\n",
    "chans = len(sem_dict)\n",
    "\n",
    "lut_in = [0, 20, 50, 100, 150, 255]\n",
    "lut_out = [0, 100, 180, 220, 240, 255]\n",
    "lut_8u = np.interp(np.arange(0, 256), lut_in, lut_out).astype(np.uint8)\n",
    "\n",
    "spec = 'stan'\n",
    "train_data_dir = 'training_data/64crop_size/9labels/1red/'\n",
    "\n",
    "now = datetime.now() # current date and time\n",
    "date = now.strftime(\"%d\")+now.strftime(\"%b\").lower()\n",
    "print(date)\n",
    "\n",
    "# filename = 'IRI_models/'+date+'_'+str(step)+'px_steps_'+spec+'_paths'\n",
    "# filename1 = 'IRI_models/'+date+'_'+str(step)+'px_steps_'+spec+'_vels'\n",
    "# filename2 = 'IRI_models/'+date+'_'+str(step)+'px_steps_'+spec+'_stops'\n",
    "filename = 'IRI_models/final5_9labels'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADDED BACK NORMALIZATION AND AUGMENTATION\n",
    "tried editing dropout (there is a *0.01, remove it)\n",
    "set red to 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data and training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing map stanford_bookstore0 (11/16)\n",
      "train list: ['stanford_gates2', 'stanford_coupa1', 'stanford_bookstore0', 'stanford_nexus0', 'stanford_little3', 'stanford_coupa0', 'stanford_bookstore4', 'stanford_deathCircle0', 'stanford_hyang2', 'stanford_hyang3', 'stanford_nexus1', 'stanford_gates6']\n",
      "test list: ['stanford_hyang4']\n",
      "val list: ['stanford_coupa2', 'stanford_coupa3', 'stanford_hyang10']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mdir\u001b[39m \u001b[38;5;241m=\u001b[39m train_data_dir\u001b[38;5;241m+\u001b[39mdata_dir\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;28mdir\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_dir \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mdir\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 21\u001b[0m train_x_aux \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/train_X.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m sizes \u001b[38;5;241m=\u001b[39m train_x_aux[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     23\u001b[0m train_x_aux \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdelete(train_x_aux, [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/npyio.py:1373\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1371\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1373\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m            \u001b[49m\u001b[43munpack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/npyio.py:1016\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     data \u001b[38;5;241m=\u001b[39m _preprocess_comments(data, comments, encoding)\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read_dtype_via_object_chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1016\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_filelike\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimaginary_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimaginary_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiplines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilelike\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilelike\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbyte_converters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbyte_converters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;66;03m# This branch reads the file into chunks of object arrays and then\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;66;03m# casts them to the desired actual dtype.  This ensures correct\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m     \u001b[38;5;66;03m# string-length and datetime-unit discovery (like `arr.astype()`).\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m     \u001b[38;5;66;03m# Due to chunking, certain error reports are less clear, currently.\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filelike:\n",
      "File \u001b[0;32m/usr/lib/python3.10/codecs.py:331\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.getstate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m     IncrementalDecoder\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetstate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;66;03m# additional state info is always 0\u001b[39;00m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetstate\u001b[39m(\u001b[38;5;28mself\u001b[39m, state):\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;66;03m# ignore additional state info\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# if True:\n",
    "#     index = 0\n",
    "#     map = map_list[index]\n",
    "\n",
    "for index, map in enumerate(map_list[:]):\n",
    "    index = index\n",
    "    print(f'Processing map {map} ({index+1}/{len(map_list)})')\n",
    "    train_list = map_list.copy()\n",
    "    test_list = [train_list.pop(index)]\n",
    "    random.shuffle(train_list)\n",
    "    val_list = [train_list.pop(index%len(train_list)), train_list.pop(index%len(train_list)), train_list.pop(index%len(train_list))]\n",
    "    print(f'train list: {train_list}')\n",
    "    print(f'test list: {test_list}')\n",
    "    print(f'val list: {val_list}')\n",
    "\n",
    "    train_x = np.empty((0, div, div, chans))\n",
    "    train_y = np.empty((0, div, div))\n",
    "    for data_dir in train_list:\n",
    "        dir = train_data_dir+data_dir\n",
    "        assert os.path.exists(dir), f'data_dir {dir} does not exist'\n",
    "        train_x_aux = np.loadtxt(dir+'/train_X.csv')\n",
    "        sizes = train_x_aux[0:4].astype(int)\n",
    "        train_x_aux = np.delete(train_x_aux, [0,1,2,3])\n",
    "        train_x_aux = np.reshape(train_x_aux,sizes)\n",
    "        # train_x_aux = train_x_aux[:, :, :, :-2]\n",
    "\n",
    "        train_y_aux = np.loadtxt(dir+'/train_Y.csv')\n",
    "        sizes = train_y_aux[0:3].astype(int)\n",
    "        train_y_aux = np.delete(train_y_aux, [0,1,2])\n",
    "        train_y_aux = np.reshape(train_y_aux,sizes)\n",
    "        train_y_aux = train_y_aux/np.max(train_y_aux)\n",
    "\n",
    "        train_x = np.append(train_x, train_x_aux, axis=0)\n",
    "        train_y = np.append(train_y, train_y_aux, axis=0)\n",
    "\n",
    "    val_x = np.empty((0, div, div, chans))\n",
    "    val_y = np.empty((0, div, div))\n",
    "    for data_dir in val_list:\n",
    "        dir = train_data_dir+data_dir\n",
    "        assert os.path.exists(dir), f'data_dir {dir} does not exist'\n",
    "        val_x_aux = np.loadtxt(dir+'/train_X.csv')\n",
    "        sizes = val_x_aux[0:4].astype(int)\n",
    "        val_x_aux = np.delete(val_x_aux, [0,1,2,3])\n",
    "        val_x_aux = np.reshape(val_x_aux,sizes)\n",
    "        # val_x_aux = val_x_aux[:, :, :, :-2]\n",
    "\n",
    "        val_y_aux = np.loadtxt(dir+'/train_Y.csv')\n",
    "        sizes = val_y_aux[0:3].astype(int)\n",
    "        val_y_aux = np.delete(val_y_aux, [0,1,2])\n",
    "        val_y_aux = np.reshape(val_y_aux,sizes)\n",
    "        val_y_aux = val_y_aux/np.max(val_y_aux)\n",
    "\n",
    "        val_x = np.append(val_x, val_x_aux, axis=0)\n",
    "        val_y = np.append(val_y, val_y_aux, axis=0)\n",
    "\n",
    "    # Create a MirroredStrategy.\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "    # Open a strategy scope.\n",
    "    with strategy.scope():\n",
    "\n",
    "        \n",
    "        # CNN-11  |  CNN-21  |  CNN-31\n",
    "        fil_array = [4,8,8]                         #Num filters first conv: 4, 8 or 8\n",
    "        lay_array = [1,3,5]                         #Layers per dense block: 1, 3 or 5\n",
    "        learn_array = [8.71e-5,3.72e-4,1.51e-4]     #Learning rates\n",
    "        decaylearn_array = [0.9984,0.9984,0.9985]   #Learning rate decays\n",
    "        wdecay_array = [1.11e-6,5.53e-7,4.58e-5]    #Weight decays\n",
    "        dropout_array = [0.307,0.120,0.349]         #Dropout probability\n",
    "\n",
    "        arc = 2                                     #[0,1,2]\n",
    "\n",
    "        filters = fil_array[arc]\n",
    "        layers_in_dense = lay_array[arc]\n",
    "\n",
    "        tf.random.set_seed(0)\n",
    "        dropout_array[arc] = dropout_array[arc] #* 0.01\n",
    "\n",
    "        def dense_factor(inputs):\n",
    "            h_1 = layers.BatchNormalization()(inputs)\n",
    "            output = layers.Conv2D(32, (3,3), padding='same', activation='relu')(h_1)\n",
    "            return output\n",
    "\n",
    "        def dense_block(inputs, upsampling):\n",
    "            concatenated_inputs = inputs\n",
    "            concatenated_inputs_less = []\n",
    "            for i in range(layers_in_dense):\n",
    "                x = dense_factor(concatenated_inputs)\n",
    "                concatenated_inputs = layers.concatenate([concatenated_inputs, x], axis=3)\n",
    "                if i == 0:\n",
    "                    concatenated_inputs_less = x\n",
    "                else:\n",
    "                    concatenated_inputs_less = layers.concatenate([concatenated_inputs_less, x], axis=3)\n",
    "                    if i == layers_in_dense - 1 and upsampling:\n",
    "                        concatenated_inputs = concatenated_inputs_less\n",
    "\n",
    "            concatenated_inputs = layers.Dropout(dropout_array[arc])(concatenated_inputs)\n",
    "\n",
    "            return concatenated_inputs\n",
    "\n",
    "        # norm_layer = layers.Normalization(axis=None)\n",
    "        # norm_layer.adapt(train_x)\n",
    "\n",
    "        input_img = layers.Input(shape=(div, div, chans))\n",
    "\n",
    "        # augment_input = norm_layer(input_img)\n",
    "        # augment_input = layers.RandomRotation(factor=0.5)(augment_input)\n",
    "        # augment_input = layers.RandomFlip(mode='horizontal_and_vertical')(augment_input)\n",
    "        # augment_input = layers.RandomZoom(height_factor=0.2, width_factor=0.2)(augment_input)\n",
    "\n",
    "        lays = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(input_img)\n",
    "        filters = filters+2\n",
    "        lays = dense_block(lays,False)\n",
    "        layerX = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(lays)\n",
    "        filters = filters+1\n",
    "        lays = layers.MaxPooling2D((2, 2), strides=2)(layerX)\n",
    "        lays = dense_block(lays,False)\n",
    "        layerY = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(lays)\n",
    "        lays = layers.MaxPooling2D((2, 2), strides=2)(layerY)\n",
    "\n",
    "        lays = dense_block(lays,True)\n",
    "\n",
    "        lays = layers.Conv2DTranspose(filters, (3, 3), strides=2, padding='same')(lays)\n",
    "        lays = layers.Add()([layerY,lays])\n",
    "        lays = dense_block(lays,True)\n",
    "        filters = filters-1\n",
    "        lays = layers.Conv2DTranspose(filters, (3, 3), strides=2, padding='same')(lays)\n",
    "        lays = layers.Add()([layerX,lays])\n",
    "        lays = dense_block(lays,False)\n",
    "        filters = filters-2\n",
    "        lays = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(lays)\n",
    "        lays = layers.Dense(units=2, activation='softmax')(lays)\n",
    "\n",
    "\n",
    "        model = models.Model(input_img, lays)\n",
    "\n",
    "        # model.summary()\n",
    "\n",
    "        def get_lr_metric(optimizer):\n",
    "            def lr(y_true, y_pred):\n",
    "                return optimizer._decayed_lr(tf.float32) # I use ._decayed_lr method instead of .lr\n",
    "            return lr\n",
    "\n",
    "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "                            initial_learning_rate=learn_array[arc],\n",
    "                            decay_steps=10,\n",
    "                            decay_rate=decaylearn_array[arc])\n",
    "\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule,weight_decay=wdecay_array[arc])\n",
    "        lr_metric = get_lr_metric(opt)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=opt,\n",
    "            # Loss function to minimize\n",
    "            loss='binary_crossentropy',\n",
    "            # List of metrics to monitor\n",
    "            metrics=['mean_squared_error'],\n",
    "        ) \n",
    "\n",
    "    my_callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=15),\n",
    "        # tf.keras.callbacks.ModelCheckpoint(filepath='IRI_models/model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        x=train_x,\n",
    "        y=np.stack((train_y,1-train_y),axis=3),\n",
    "        batch_size=400,\n",
    "        epochs=100, #100\n",
    "        validation_data=(val_x, np.stack((val_y,1-val_y),axis=3)),\n",
    "        callbacks=my_callbacks,\n",
    "    )\n",
    "\n",
    "    # if not os.path.exists(filename):\n",
    "    model.save(filename+'_'+test_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aux_x = validation_x\n",
    "# aux_y = validation_y\n",
    "\n",
    "# output = model.predict(aux_x,verbose=0)[:,:,:,0]\n",
    "\n",
    "# n = num_validation  # How many images we will display\n",
    "# plt.figure(figsize=(25, 5))\n",
    "# for i in range(n):\n",
    "#     # Display original\n",
    "#     ax = plt.subplot(2, n, i + 1)\n",
    "#     plt.imshow(np.multiply(np.stack((aux_x[i,:,:,0],aux_x[i,:,:,0],aux_x[i,:,:,0]),axis=2), np.stack((np.full(aux_y[i].shape,1),1-aux_y[i],1-aux_y[i]),axis=2)))\n",
    "#     ax.get_xaxis().set_visible(False)\n",
    "#     ax.get_yaxis().set_visible(False)\n",
    "\n",
    "#     # Display reconstruction\n",
    "#     ax = plt.subplot(2, n, i + 1 + n)\n",
    "#     plt.imshow(np.multiply(np.stack((aux_x[i,:,:,0],aux_x[i,:,:,0],aux_x[i,:,:,0]),axis=2), np.stack((np.full(output[i].shape,1),1-output[i],1-output[i]),axis=2)))\n",
    "#     ax.get_xaxis().set_visible(False)\n",
    "#     ax.get_yaxis().set_visible(False)\n",
    "# # Display original\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss, test_acc = model.evaluate(aux_x,  np.stack((val_y,1-val_y),axis=3), verbose=2)\n",
    "\n",
    "plt.plot(history.history['mean_squared_error'], label='mean_squared_error')\n",
    "plt.plot(history.history['val_mean_squared_error'], label = 'val_mean_squared_error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label = 'loss')\n",
    "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTES"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Add benches, tables & chairs\n",
    "- [x] Add also velocity information (two different maps for velocities and regions of stop)\n",
    "- [x]    80% of time people pass stair and not sit\n",
    "- [x]    white noise velocity \n",
    "- [ ] Add heading of motion (directional velocity)\n",
    "- [ ] MAYBE Time of the day\n",
    "\n",
    "- [ ] mobility: main cues they are looking for (narrow places, which other criterias?) \"Criterium\" what do we need to look for\n",
    "(from computer vision)\n",
    "\n",
    "- [ ] collect data with following robot/static robot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add the velocity and stop information is enough novelty?\n",
    "- Could the same network handle everything (all outputs: occupancy, velocity, stops)? First try seems not.. (only with occupancy and velocity.. but it could be my fault! binary crossentropy!!!)\n",
    "- Could same network handle both people, cars and bicycles?\n",
    "- Paper \"Learning Occupancy Priors of Human Motion From Semantic Maps of Urban Enviroments\" uses KL-divergence to compare to baselines.\n",
    "    They say that \"only a few methods explicitly highlight the performance in new environments outside the training scenario\"\n",
    "    Their future work section: \"Furthermore, we plan to validate semapp with on-the-fly semantics estimation and extend it to first-person view for application in automated driving to infer potential pedestrians’ entrance points to the road.\"\n",
    "\n",
    "\n",
    "- [x] Add barriers: completely close passage or partially\n",
    "- [x] validate w/ simulation and exp (stanford dataset)\n",
    "- [ ] check reference of new paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mobility environment cues:\n",
    "- what is important in mobility: velocity, narrow spaces, individual or group\n",
    "- STOP is important"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
